{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_object.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the data from sample.csv using np.genfromtxt\n",
    "data = np.genfromtxt('sample.csv', delimiter=',')\n",
    "# # Load the data from Sample.txt\n",
    "# data = np.loadtxt('sample.csv')\n",
    "\n",
    "# Create a StandardScaler object and fit_transform the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Store the scaler object for reproducibility\n",
    "joblib.dump(scaler, 'scaler_object.joblib')\n",
    "\n",
    "# Now scaled_data contains the normalized dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(scaled_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_data and test_data now contain the training and testing datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets as numpy files\n",
    "np.save('train_data.npy', train_data)\n",
    "np.save('test_data.npy', test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output : Predictions match!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "# Assume you already have the train_data and test_data loaded\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Assess the prediction on the test dataset\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Store the trained model for reproducibility\n",
    "joblib.dump(model, 'linear_regression_model.joblib')\n",
    "\n",
    "# Now, in another Python file, you can load the model and test data for prediction\n",
    "# Load the model\n",
    "loaded_model = joblib.load('linear_regression_model.joblib')\n",
    "\n",
    "# Make predictions on the test data\n",
    "loaded_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Check if the predictions are the same\n",
    "if np.array_equal(predictions, loaded_predictions):\n",
    "    print(\"Output : Predictions match!\")\n",
    "else:\n",
    "    print(\"Output : Predictions differ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
